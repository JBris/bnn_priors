{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bnn_priors.models import DenseNet\n",
    "from bnn_priors.data import CIFAR10\n",
    "from bnn_priors import prior\n",
    "from bnn_priors.models import RegressionModel, LinearPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ResNet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.py\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    '''Pre-activation version of the original Bottleneck module.'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = batchnorm(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out = self.bn3(out)\n",
    "        out = self.conv3(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, bn=True):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.bn = bn\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, bn=self.bn))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18(bn=True):\n",
    "    return PreActResNet(PreActBlock, [2,2,2,2], bn=bn)\n",
    "\n",
    "def PreActResNet34(bn=True):\n",
    "    return PreActResNet(PreActBlock, [3,4,6,3], bn=bn)\n",
    "\n",
    "def PreActResNet50(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,4,6,3], bn=bn)\n",
    "\n",
    "def PreActResNet101(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,4,23,3], bn=bn)\n",
    "\n",
    "def PreActResNet152(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,8,36,3], bn=bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10()\n",
    "\n",
    "dataloader_train = DataLoader(data.norm.train, batch_size=32, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(data.norm.test, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 7/1562 [00:00<00:39, 39.25it/s, loss=0.73]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 56.3 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 6/1562 [00:00<00:41, 37.31it/s, loss=0.74]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 71.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 7/1562 [00:00<00:39, 39.51it/s, loss=0.50]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 75.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 7/1562 [00:00<00:41, 37.72it/s, loss=0.26]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 80.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 81.4 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "lr = 5e-4\n",
    "\n",
    "net = PreActResNet18(bn=True).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    with tqdm(desc=f\"Epoch {epoch}\", total=len(dataloader_train), leave=False) as pbar:\n",
    "        for batch_x, batch_y in dataloader_train:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = net(batch_x)\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update()\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.2f}\"})\n",
    "            \n",
    "    total_acc = 0.\n",
    "    num_batches = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            y_pred = net(batch_x)\n",
    "            total_acc += y_pred.argmax(axis=1).eq(batch_y).float().mean().item()\n",
    "            num_batches += 1\n",
    "    acc = total_acc/num_batches\n",
    "    print(f\"Epoch {epoch}: Test accuracy = {acc*100:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Bayesian CNNs analogous to the DenseNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Conv2d):\n",
    "    def __init__(self, weight_prior, bias_prior=None, stride=1,\n",
    "            padding=0, dilation=1, groups=1, padding_mode='zeros'):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.stride = nn.modules.utils._pair(stride)\n",
    "        self.padding = nn.modules.utils._pair(padding)\n",
    "        self.dilation = nn.modules.utils._pair(dilation)\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        self.transposed = False\n",
    "        self.output_padding = nn.modules.utils._pair(0)\n",
    "        \n",
    "        (self.out_channels, in_channels, ksize_0, ksize_1) = weight_prior.p.shape\n",
    "        self.in_channels = in_channels * self.groups\n",
    "        self.kernel_size = (ksize_0, ksize_1)\n",
    "        self.weight_prior = weight_prior\n",
    "        self.bias_prior = bias_prior\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.weight_prior()\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return (None if self.bias_prior is None else self.bias_prior())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2dPrior(in_channels, out_channels, kernel_size, stride=1,\n",
    "            padding=0, dilation=1, groups=1, padding_mode='zeros',\n",
    "            prior_w=prior.Normal, loc_w=0., std_w=1., prior_b=prior.Normal,\n",
    "            loc_b=0., std_b=1., scaling_fn=None):\n",
    "    if scaling_fn is None:\n",
    "        def scaling_fn(std, dim):\n",
    "            return std/dim**0.5\n",
    "    kernel_size = nn.modules.utils._pair(kernel_size)\n",
    "    bias_prior = prior_b((out_channels,), 0., std_b) if prior_b is not None else None\n",
    "    return Conv2d(weight_prior=prior_w((out_channels, in_channels//groups, kernel_size[0], kernel_size[1]),\n",
    "                                       loc_w, scaling_fn(std_w, in_channels)),\n",
    "                  bias_prior=bias_prior,\n",
    "                 stride=stride, padding=padding, dilation=dilation,\n",
    "                  groups=groups, padding_mode=padding_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_test = Conv2dPrior(3, 16, 3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(\n",
       "  3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "  (weight_prior): Normal()\n",
       "  (bias_prior): Normal()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_test(batch_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True,\n",
    "                 prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "                 prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "                scaling_fn=None):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = Conv2dPrior(in_planes, planes, kernel_size=3, stride=stride, padding=1,\n",
    "                                 prior_w=prior_w, loc_w=loc_w, std_w=std_w,\n",
    "                                 prior_b=None, scaling_fn=scaling_fn)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = Conv2dPrior(planes, planes, kernel_size=3, stride=1, padding=1,\n",
    "                                 prior_w=prior_w, loc_w=loc_w, std_w=std_w,\n",
    "                                 prior_b=None, scaling_fn=scaling_fn)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, bn=True,\n",
    "                 prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "                 prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "                scaling_fn=None):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.bn = bn\n",
    "        self.prior_w = prior_w\n",
    "        self.loc_w = loc_w\n",
    "        self.std_w = std_w\n",
    "        self.prior_b = prior_b\n",
    "        self.loc_b = loc_b\n",
    "        self.std_b = std_b\n",
    "        self.scaling_fn = scaling_fn\n",
    "\n",
    "        self.conv1 = Conv2dPrior(3, 64, kernel_size=3, stride=1, padding=1, prior_b=None,\n",
    "                           prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                           scaling_fn=self.scaling_fn)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = LinearPrior(512*block.expansion, num_classes,\n",
    "                            prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                            prior_b=self.prior_b, loc_b=self.loc_b, std_b=self.std_b,\n",
    "                            scaling_fn=self.scaling_fn)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, bn=self.bn,\n",
    "                                prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                                prior_b=self.prior_b, loc_b=self.loc_b, std_b=self.std_b,\n",
    "                                scaling_fn=self.scaling_fn))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18(noise_std=1.,\n",
    "             prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "             prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "            scaling_fn=None, bn=True):\n",
    "    return RegressionModel(PreActResNet(PreActBlock,\n",
    "                                        [2,2,2,2], bn=bn,\n",
    "                                        prior_w=prior_w,\n",
    "                                       loc_w=loc_w,\n",
    "                                       std_w=std_w,\n",
    "                                       prior_b=prior_b,\n",
    "                                       loc_b=loc_b,\n",
    "                                       std_b=std_b,\n",
    "                                       scaling_fn=scaling_fn,), noise_std)\n",
    "\n",
    "def PreActResNet34(noise_std=1.,\n",
    "             prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "             prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "            scaling_fn=None, bn=True):\n",
    "    return RegressionModel(PreActResNet(PreActBlock,\n",
    "                                        [3,4,6,3], bn=bn,\n",
    "                                        prior_w=prior_w,\n",
    "                                       loc_w=loc_w,\n",
    "                                       std_w=std_w,\n",
    "                                       prior_b=prior_b,\n",
    "                                       loc_b=loc_b,\n",
    "                                       std_b=std_b,\n",
    "                                       scaling_fn=scaling_fn,), noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_test = PreActResNet18(bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionModel(\n",
       "  (net): PreActResNet(\n",
       "    (conv1): Conv2d(\n",
       "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_prior): Normal()\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "      )\n",
       "      (1): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): PreActBlock(\n",
       "        (bn1): Identity()\n",
       "        (conv1): Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (conv2): Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (weight_prior): Normal()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(\n",
       "      in_features=512, out_features=10, bias=True\n",
       "      (weight_prior): Normal()\n",
       "      (bias_prior): Normal()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3432e+07, -1.5418e+07, -7.5873e+07, -1.5155e+08, -1.8143e+08,\n",
       "          2.0325e+08,  4.7009e+07, -9.8311e+07, -6.6515e+07, -1.3548e+07],\n",
       "        [-3.0543e+07, -2.3680e+07, -2.7173e+07, -9.8132e+07, -8.5382e+07,\n",
       "          1.0743e+08,  2.9502e+07, -3.3338e+07, -3.1310e+07,  2.5502e+06],\n",
       "        [-3.1892e+07, -2.0117e+07, -3.0110e+07, -9.8610e+07, -1.0487e+08,\n",
       "          8.6862e+07,  2.4562e+07, -4.1332e+07, -4.6408e+07,  1.1651e+07],\n",
       "        [-1.3582e+07, -8.2427e+06, -2.3244e+07, -7.6444e+07, -9.0692e+07,\n",
       "          1.0123e+08,  3.9290e+07, -3.6177e+07, -2.7057e+07,  3.6430e+07],\n",
       "        [-4.4095e+07, -3.9576e+07, -3.0360e+07, -1.1227e+08, -1.4138e+08,\n",
       "          1.4821e+08,  6.2264e+07, -5.6455e+07, -6.8498e+07,  8.3475e+06],\n",
       "        [-3.7507e+07, -1.7410e+07, -2.5262e+07, -8.8539e+07, -1.0218e+08,\n",
       "          9.9186e+07,  4.3815e+07, -3.9756e+07, -5.8049e+07,  2.4017e+07],\n",
       "        [-1.2622e+07, -1.5140e+07, -1.9202e+07, -4.9003e+07, -5.1649e+07,\n",
       "          5.5036e+07,  2.5081e+07, -2.2248e+07, -2.3426e+07, -6.7272e+06],\n",
       "        [-2.5198e+07, -3.8426e+06, -3.7657e+07, -6.6202e+07, -6.8460e+07,\n",
       "          8.7785e+07,  2.3917e+07, -2.2053e+07, -3.9310e+07, -8.9182e+06],\n",
       "        [-2.4158e+07, -1.7271e+07, -3.4308e+07, -7.8800e+07, -7.9235e+07,\n",
       "          7.4469e+07,  3.9507e+07, -2.8820e+07, -3.2720e+07, -4.4085e+06],\n",
       "        [-1.6548e+07, -2.0883e+07, -2.0281e+07, -7.5407e+07, -6.8608e+07,\n",
       "          7.9270e+07,  1.5298e+07, -1.7422e+07, -2.5816e+07, -5.0385e+06],\n",
       "        [-3.4727e+07, -8.4528e+06, -2.7288e+07, -1.0082e+08, -1.0614e+08,\n",
       "          1.0536e+08,  5.2238e+07, -4.1571e+07, -6.1602e+07,  1.2084e+07],\n",
       "        [-2.5284e+07, -2.7351e+07, -4.1525e+07, -7.9029e+07, -8.1592e+07,\n",
       "          8.4113e+07,  4.5241e+07, -3.9865e+07, -4.2465e+07, -3.5606e+06],\n",
       "        [-2.0218e+07, -1.6765e+07, -4.5712e+07, -8.2558e+07, -9.0855e+07,\n",
       "          7.7659e+07,  2.7259e+07, -2.9438e+07, -3.9039e+07,  5.9602e+06],\n",
       "        [-1.9945e+07, -6.8332e+06, -2.2472e+07, -4.3988e+07, -6.0008e+07,\n",
       "          5.9561e+07,  2.6148e+07, -2.7294e+07, -3.3903e+07, -1.3211e+07],\n",
       "        [-2.2878e+07, -7.8441e+06, -2.2881e+07, -5.1146e+07, -5.6831e+07,\n",
       "          5.2467e+07,  1.9121e+07, -3.3178e+07, -2.8487e+07,  5.8319e+06],\n",
       "        [-1.7307e+07, -2.4468e+07, -4.4244e+07, -1.0376e+08, -9.3447e+07,\n",
       "          9.1322e+07,  3.9071e+07, -4.9190e+07, -3.7437e+07, -1.0492e+07],\n",
       "        [-4.0334e+07, -1.9333e+07, -7.7524e+06, -7.7164e+07, -1.0056e+08,\n",
       "          1.1372e+08,  3.5917e+07, -5.6976e+07, -4.7163e+07,  5.7944e+06],\n",
       "        [-1.4871e+07, -1.2722e+07, -9.9029e+06, -6.1227e+07, -7.4436e+07,\n",
       "          6.4798e+07,  2.0180e+07, -8.3315e+06, -3.6338e+07,  2.9218e+06],\n",
       "        [-2.0023e+07, -2.8863e+07, -1.7490e+07, -7.7782e+07, -7.7193e+07,\n",
       "          7.7176e+07,  4.2656e+07, -4.2221e+07, -3.4265e+07,  1.9640e+07],\n",
       "        [-1.4492e+07, -4.9036e+06, -2.5214e+07, -7.0245e+07, -7.2538e+07,\n",
       "          7.9233e+07,  2.7285e+07, -2.5008e+07, -2.4772e+07,  2.7483e+06],\n",
       "        [-1.4941e+07, -2.0256e+07, -1.5449e+07, -6.8529e+07, -7.8596e+07,\n",
       "          7.5245e+07,  2.3341e+07, -3.1011e+07, -4.1148e+07,  1.0141e+07],\n",
       "        [-2.5716e+07, -3.5264e+07, -3.8146e+07, -1.2276e+08, -1.1405e+08,\n",
       "          1.0856e+08,  2.2057e+07, -4.7971e+07, -5.2658e+07,  1.3287e+07],\n",
       "        [-4.3266e+07, -1.1381e+07, -6.1153e+07, -9.7082e+07, -1.2955e+08,\n",
       "          1.4657e+08,  5.9632e+07, -3.9621e+07, -6.3521e+07, -1.2861e+07],\n",
       "        [-2.4917e+07, -6.8920e+06, -9.0365e+06, -7.6514e+07, -8.4874e+07,\n",
       "          9.7219e+07,  3.2380e+07, -3.7099e+07, -4.4466e+07,  2.9117e+06],\n",
       "        [-2.5394e+07, -8.9056e+05, -1.3718e+07, -6.2602e+07, -7.0599e+07,\n",
       "          7.3993e+07,  2.6301e+07, -1.6762e+07, -2.6060e+07,  1.0786e+07],\n",
       "        [-1.0566e+07, -1.6665e+07, -3.0656e+07, -6.0499e+07, -5.7225e+07,\n",
       "          7.8027e+07,  2.9888e+07, -2.6247e+07, -3.3671e+07,  2.9156e+06],\n",
       "        [-1.7945e+07, -2.0438e+07, -2.2189e+07, -7.5122e+07, -6.2489e+07,\n",
       "          7.1687e+07,  1.7649e+07, -2.8329e+07, -4.2325e+07, -5.3612e+04],\n",
       "        [-3.8243e+07,  4.4429e+05, -3.8966e+07, -9.1298e+07, -1.0635e+08,\n",
       "          1.0033e+08,  3.4974e+07, -4.5863e+07, -4.6299e+07, -6.0086e+06],\n",
       "        [-4.4556e+07, -4.1023e+07, -4.3662e+07, -9.0723e+07, -9.0437e+07,\n",
       "          1.1399e+08,  4.1400e+07, -5.5510e+07, -4.7179e+07, -1.7862e+07],\n",
       "        [-3.3523e+07, -1.5660e+07, -2.1337e+07, -8.2642e+07, -1.1107e+08,\n",
       "          9.4622e+07,  3.2800e+07, -3.3107e+07, -4.8216e+07, -3.1108e+06],\n",
       "        [-3.3259e+07, -2.5610e+07, -2.6460e+07, -8.0976e+07, -8.4483e+07,\n",
       "          9.4935e+07,  4.9030e+07, -4.9645e+07, -3.4972e+07, -2.4030e+06],\n",
       "        [-4.6341e+06, -1.2086e+07, -1.8353e+07, -4.7991e+07, -5.2436e+07,\n",
       "          4.5237e+07,  2.5286e+07, -1.4562e+07, -2.4177e+07, -9.8292e+05]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_test(batch_x).mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnn_priors.models import PreActResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10()\n",
    "\n",
    "dataloader_train = DataLoader(data.norm.train, batch_size=32, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(data.norm.test, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 7/1562 [00:00<00:41, 37.80it/s, loss=1.25]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 51.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 6/1562 [00:00<00:44, 35.28it/s, loss=0.86]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 62.1 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 7/1562 [00:00<00:39, 38.88it/s, loss=0.66]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 73.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 7/1562 [00:00<00:42, 36.63it/s, loss=0.32]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 76.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 77.5 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "lr = 5e-4\n",
    "\n",
    "net = PreActResNet18(bn=True).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    with tqdm(desc=f\"Epoch {epoch}\", total=len(dataloader_train), leave=False) as pbar:\n",
    "        for batch_x, batch_y in dataloader_train:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = net(batch_x).mean\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update()\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.2f}\"})\n",
    "            \n",
    "    total_acc = 0.\n",
    "    num_batches = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            y_pred = net(batch_x).mean\n",
    "            total_acc += y_pred.argmax(axis=1).eq(batch_y).float().mean().item()\n",
    "            num_batches += 1\n",
    "    acc = total_acc/num_batches\n",
    "    print(f\"Epoch {epoch}: Test accuracy = {acc*100:.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

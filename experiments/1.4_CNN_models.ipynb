{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bnn_priors.models import DenseNet\n",
    "from bnn_priors.data import CIFAR10\n",
    "from bnn_priors import prior\n",
    "from bnn_priors.models import RegressionModel, LinearPrior, ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ResNet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.py\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    '''Pre-activation version of the original Bottleneck module.'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = batchnorm(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out = self.bn3(out)\n",
    "        out = self.conv3(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, bn=True):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.bn = bn\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, bn=self.bn))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18(bn=True):\n",
    "    return PreActResNet(PreActBlock, [2,2,2,2], bn=bn)\n",
    "\n",
    "def PreActResNet34(bn=True):\n",
    "    return PreActResNet(PreActBlock, [3,4,6,3], bn=bn)\n",
    "\n",
    "def PreActResNet50(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,4,6,3], bn=bn)\n",
    "\n",
    "def PreActResNet101(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,4,23,3], bn=bn)\n",
    "\n",
    "def PreActResNet152(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,8,36,3], bn=bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10(device=device)\n",
    "\n",
    "dataloader_train = DataLoader(data.norm.train, batch_size=32, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(data.norm.test, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 7/1562 [00:00<00:40, 37.93it/s, loss=0.92]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 54.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 6/1562 [00:00<00:41, 37.09it/s, loss=0.70]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 68.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 6/1562 [00:00<00:42, 36.94it/s, loss=0.60]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 76.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 6/1562 [00:00<00:48, 31.95it/s, loss=0.60]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 77.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 80.5 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "lr = 5e-4\n",
    "\n",
    "net = PreActResNet18(bn=True).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    with tqdm(desc=f\"Epoch {epoch}\", total=len(dataloader_train), leave=False) as pbar:\n",
    "        for batch_x, batch_y in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = net(batch_x)\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update()\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.2f}\"})\n",
    "            \n",
    "    total_acc = 0.\n",
    "    num_batches = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            y_pred = net(batch_x)\n",
    "            total_acc += y_pred.argmax(axis=1).eq(batch_y).float().mean().item()\n",
    "            num_batches += 1\n",
    "    acc = total_acc/num_batches\n",
    "    print(f\"Epoch {epoch}: Test accuracy = {acc*100:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Bayesian CNNs analogous to the DenseNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Conv2d):\n",
    "    def __init__(self, weight_prior, bias_prior=None, stride=1,\n",
    "            padding=0, dilation=1, groups=1, padding_mode='zeros'):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.stride = nn.modules.utils._pair(stride)\n",
    "        self.padding = nn.modules.utils._pair(padding)\n",
    "        self.dilation = nn.modules.utils._pair(dilation)\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        self.transposed = False\n",
    "        self.output_padding = nn.modules.utils._pair(0)\n",
    "        \n",
    "        (self.out_channels, in_channels, ksize_0, ksize_1) = weight_prior.p.shape\n",
    "        self.in_channels = in_channels * self.groups\n",
    "        self.kernel_size = (ksize_0, ksize_1)\n",
    "        self.weight_prior = weight_prior\n",
    "        self.bias_prior = bias_prior\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.weight_prior()\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return (None if self.bias_prior is None else self.bias_prior())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2dPrior(in_channels, out_channels, kernel_size, stride=1,\n",
    "            padding=0, dilation=1, groups=1, padding_mode='zeros',\n",
    "            prior_w=prior.Normal, loc_w=0., std_w=1., prior_b=prior.Normal,\n",
    "            loc_b=0., std_b=1., scaling_fn=None):\n",
    "    if scaling_fn is None:\n",
    "        def scaling_fn(std, dim):\n",
    "            return std/dim**0.5\n",
    "    kernel_size = nn.modules.utils._pair(kernel_size)\n",
    "    bias_prior = prior_b((out_channels,), 0., std_b) if prior_b is not None else None\n",
    "    return Conv2d(weight_prior=prior_w((out_channels, in_channels//groups, kernel_size[0], kernel_size[1]),\n",
    "                                       loc_w, scaling_fn(std_w, in_channels)),\n",
    "                  bias_prior=bias_prior,\n",
    "                 stride=stride, padding=padding, dilation=dilation,\n",
    "                  groups=groups, padding_mode=padding_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True,\n",
    "                 prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "                 prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "                scaling_fn=None):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = Conv2dPrior(in_planes, planes, kernel_size=3, stride=stride, padding=1,\n",
    "                                 prior_w=prior_w, loc_w=loc_w, std_w=std_w,\n",
    "                                 prior_b=None, scaling_fn=scaling_fn)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = Conv2dPrior(planes, planes, kernel_size=3, stride=1, padding=1,\n",
    "                                 prior_w=prior_w, loc_w=loc_w, std_w=std_w,\n",
    "                                 prior_b=None, scaling_fn=scaling_fn)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, bn=True,\n",
    "                 prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "                 prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "                scaling_fn=None):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.bn = bn\n",
    "        self.prior_w = prior_w\n",
    "        self.loc_w = loc_w\n",
    "        self.std_w = std_w\n",
    "        self.prior_b = prior_b\n",
    "        self.loc_b = loc_b\n",
    "        self.std_b = std_b\n",
    "        self.scaling_fn = scaling_fn\n",
    "\n",
    "        self.conv1 = Conv2dPrior(3, 64, kernel_size=3, stride=1, padding=1, prior_b=None,\n",
    "                           prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                           scaling_fn=self.scaling_fn)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = LinearPrior(512*block.expansion, num_classes,\n",
    "                            prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                            prior_b=self.prior_b, loc_b=self.loc_b, std_b=self.std_b,\n",
    "                            scaling_fn=self.scaling_fn)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, bn=self.bn,\n",
    "                                prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                                prior_b=self.prior_b, loc_b=self.loc_b, std_b=self.std_b,\n",
    "                                scaling_fn=self.scaling_fn))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18(softmax_temp=1.,\n",
    "             prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "             prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "            scaling_fn=None, bn=True):\n",
    "    return ClassificationModel(PreActResNet(PreActBlock,\n",
    "                                        [2,2,2,2], bn=bn,\n",
    "                                        prior_w=prior_w,\n",
    "                                       loc_w=loc_w,\n",
    "                                       std_w=std_w,\n",
    "                                       prior_b=prior_b,\n",
    "                                       loc_b=loc_b,\n",
    "                                       std_b=std_b,\n",
    "                                       scaling_fn=scaling_fn,), softmax_temp)\n",
    "\n",
    "def PreActResNet34(softmax_temp=1.,\n",
    "             prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "             prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "            scaling_fn=None, bn=True):\n",
    "    return ClassificationModel(PreActResNet(PreActBlock,\n",
    "                                        [3,4,6,3], bn=bn,\n",
    "                                        prior_w=prior_w,\n",
    "                                       loc_w=loc_w,\n",
    "                                       std_w=std_w,\n",
    "                                       prior_b=prior_b,\n",
    "                                       loc_b=loc_b,\n",
    "                                       std_b=std_b,\n",
    "                                       scaling_fn=scaling_fn,), softmax_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnn_priors.models import PreActResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10(device=device)\n",
    "\n",
    "dataloader_train = DataLoader(data.norm.train, batch_size=32, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(data.norm.test, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 7/1562 [00:00<00:42, 36.39it/s, loss=12.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training criterion: nll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 6/1562 [00:00<00:48, 32.15it/s, loss=1.26]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 54.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 6/1562 [00:00<00:44, 35.20it/s, loss=0.77]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 61.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 6/1562 [00:00<00:49, 31.13it/s, loss=0.76]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 72.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 6/1562 [00:00<00:45, 34.16it/s, loss=0.45]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 74.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 4/1562 [00:00<01:06, 23.46it/s, loss=247.38] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 76.1 %\n",
      "Training criterion: potential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 4/1562 [00:00<01:01, 25.21it/s, loss=-57403.28]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 77.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 5/1562 [00:00<00:54, 28.52it/s, loss=-157267.64]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 74.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 4/1562 [00:00<01:02, 24.87it/s, loss=-288153.00]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 76.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 4/1562 [00:00<01:04, 24.22it/s, loss=-449243.53]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 77.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 77.3 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "lr = 5e-4\n",
    "\n",
    "net = PreActResNet18(bn=True).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "for criterion in [\"nll\", \"potential\"]:\n",
    "    print(f\"Training criterion: {criterion}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        with tqdm(desc=f\"Epoch {epoch}\", total=len(dataloader_train), leave=False) as pbar:\n",
    "            for batch_x, batch_y in dataloader_train:\n",
    "                optimizer.zero_grad()\n",
    "                if criterion == \"nll\":\n",
    "                    loss = -net.log_likelihood_avg(batch_x, batch_y, len(dataloader_train.dataset))\n",
    "                elif criterion == \"potential\":\n",
    "                    loss = net.potential_avg(batch_x, batch_y, len(dataloader_train.dataset))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.update()\n",
    "                pbar.set_postfix({\"loss\": f\"{loss.item():.2f}\"})\n",
    "\n",
    "        total_acc = 0.\n",
    "        num_batches = 0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in dataloader_test:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                y_pred = net(batch_x).probs.argmax(axis=1)\n",
    "                total_acc += y_pred.eq(batch_y).float().mean().item()\n",
    "                num_batches += 1\n",
    "        acc = total_acc/num_batches\n",
    "        print(f\"Epoch {epoch}: Test accuracy = {acc*100:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGLD inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnn_priors.inference import SGLDRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PreActResNet18(bn=True).to(device)\n",
    "\n",
    "n_samples = 20\n",
    "skip = 5\n",
    "cycles = 2\n",
    "warmup = 1000\n",
    "burnin = 1000\n",
    "lr = 5e-4\n",
    "temperature = 1.0\n",
    "momentum = 0.9\n",
    "precond_update = None\n",
    "    \n",
    "sample_epochs = n_samples * skip // cycles\n",
    "epochs_per_cycle = warmup + burnin + sample_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = SGLDRunner(model=model, dataloader=dataloader_train, epochs_per_cycle=epochs_per_cycle,\n",
    "                  warmup_epochs=warmup, sample_epochs=sample_epochs, learning_rate=lr,\n",
    "                  skip=skip, sampling_decay=True, cycles=cycles, temperature=temperature,\n",
    "                  momentum=momentum, precond_update=precond_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle 0, Sampling:   3%|▎         | 57/2050 [1:01:45<35:35:42, 64.30s/it]"
     ]
    }
   ],
   "source": [
    "mcmc.run(progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

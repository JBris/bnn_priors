{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bnn_priors.models import DenseNet\n",
    "from bnn_priors.data import CIFAR10\n",
    "from bnn_priors import prior\n",
    "from bnn_priors.models import RegressionModel, LinearPrior, ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ResNet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.py\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    '''Pre-activation version of the original Bottleneck module.'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = batchnorm(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out = self.bn3(out)\n",
    "        out = self.conv3(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, bn=True):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.bn = bn\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, bn=self.bn))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18(bn=True):\n",
    "    return PreActResNet(PreActBlock, [2,2,2,2], bn=bn)\n",
    "\n",
    "def PreActResNet34(bn=True):\n",
    "    return PreActResNet(PreActBlock, [3,4,6,3], bn=bn)\n",
    "\n",
    "def PreActResNet50(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,4,6,3], bn=bn)\n",
    "\n",
    "def PreActResNet101(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,4,23,3], bn=bn)\n",
    "\n",
    "def PreActResNet152(bn=True):\n",
    "    return PreActResNet(PreActBottleneck, [3,8,36,3], bn=bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10(device=device)\n",
    "\n",
    "dataloader_train = DataLoader(data.norm.train, batch_size=32, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(data.norm.test, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 7/1562 [00:00<00:40, 37.93it/s, loss=0.92]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 54.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 6/1562 [00:00<00:41, 37.09it/s, loss=0.70]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 68.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 6/1562 [00:00<00:42, 36.94it/s, loss=0.60]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 76.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 6/1562 [00:00<00:48, 31.95it/s, loss=0.60]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 77.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 80.5 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "lr = 5e-4\n",
    "\n",
    "net = PreActResNet18(bn=True).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    with tqdm(desc=f\"Epoch {epoch}\", total=len(dataloader_train), leave=False) as pbar:\n",
    "        for batch_x, batch_y in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = net(batch_x)\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update()\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.2f}\"})\n",
    "            \n",
    "    total_acc = 0.\n",
    "    num_batches = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            y_pred = net(batch_x)\n",
    "            total_acc += y_pred.argmax(axis=1).eq(batch_y).float().mean().item()\n",
    "            num_batches += 1\n",
    "    acc = total_acc/num_batches\n",
    "    print(f\"Epoch {epoch}: Test accuracy = {acc*100:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Bayesian CNNs analogous to the DenseNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Conv2d):\n",
    "    def __init__(self, weight_prior, bias_prior=None, stride=1,\n",
    "            padding=0, dilation=1, groups=1, padding_mode='zeros'):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.stride = nn.modules.utils._pair(stride)\n",
    "        self.padding = nn.modules.utils._pair(padding)\n",
    "        self.dilation = nn.modules.utils._pair(dilation)\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        self.transposed = False\n",
    "        self.output_padding = nn.modules.utils._pair(0)\n",
    "        \n",
    "        (self.out_channels, in_channels, ksize_0, ksize_1) = weight_prior.p.shape\n",
    "        self.in_channels = in_channels * self.groups\n",
    "        self.kernel_size = (ksize_0, ksize_1)\n",
    "        self.weight_prior = weight_prior\n",
    "        self.bias_prior = bias_prior\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.weight_prior()\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return (None if self.bias_prior is None else self.bias_prior())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2dPrior(in_channels, out_channels, kernel_size, stride=1,\n",
    "            padding=0, dilation=1, groups=1, padding_mode='zeros',\n",
    "            prior_w=prior.Normal, loc_w=0., std_w=1., prior_b=prior.Normal,\n",
    "            loc_b=0., std_b=1., scaling_fn=None):\n",
    "    if scaling_fn is None:\n",
    "        def scaling_fn(std, dim):\n",
    "            return std/dim**0.5\n",
    "    kernel_size = nn.modules.utils._pair(kernel_size)\n",
    "    bias_prior = prior_b((out_channels,), 0., std_b) if prior_b is not None else None\n",
    "    return Conv2d(weight_prior=prior_w((out_channels, in_channels//groups, kernel_size[0], kernel_size[1]),\n",
    "                                       loc_w, scaling_fn(std_w, in_channels)),\n",
    "                  bias_prior=bias_prior,\n",
    "                 stride=stride, padding=padding, dilation=dilation,\n",
    "                  groups=groups, padding_mode=padding_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, bn=True,\n",
    "                 prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "                 prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "                scaling_fn=None):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        if bn:\n",
    "            batchnorm = nn.BatchNorm2d\n",
    "        else:\n",
    "            batchnorm = nn.Identity\n",
    "        self.bn1 = batchnorm(in_planes)\n",
    "        self.conv1 = Conv2dPrior(in_planes, planes, kernel_size=3, stride=stride, padding=1,\n",
    "                                 prior_w=prior_w, loc_w=loc_w, std_w=std_w,\n",
    "                                 prior_b=None, scaling_fn=scaling_fn)\n",
    "        self.bn2 = batchnorm(planes)\n",
    "        self.conv2 = Conv2dPrior(planes, planes, kernel_size=3, stride=1, padding=1,\n",
    "                                 prior_w=prior_w, loc_w=loc_w, std_w=std_w,\n",
    "                                 prior_b=None, scaling_fn=scaling_fn)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                Conv2dPrior(in_planes, self.expansion*planes, kernel_size=1, stride=stride,\n",
    "                                 prior_w=prior_w, loc_w=loc_w, std_w=std_w,\n",
    "                                 prior_b=None, scaling_fn=scaling_fn)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv2(F.relu(out))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, bn=True,\n",
    "                 prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "                 prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "                scaling_fn=None):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.bn = bn\n",
    "        self.prior_w = prior_w\n",
    "        self.loc_w = loc_w\n",
    "        self.std_w = std_w\n",
    "        self.prior_b = prior_b\n",
    "        self.loc_b = loc_b\n",
    "        self.std_b = std_b\n",
    "        self.scaling_fn = scaling_fn\n",
    "\n",
    "        self.conv1 = Conv2dPrior(3, 64, kernel_size=3, stride=1, padding=1, prior_b=None,\n",
    "                           prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                           scaling_fn=self.scaling_fn)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = LinearPrior(512*block.expansion, num_classes,\n",
    "                            prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                            prior_b=self.prior_b, loc_b=self.loc_b, std_b=self.std_b,\n",
    "                            scaling_fn=self.scaling_fn)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, bn=self.bn,\n",
    "                                prior_w=self.prior_w, loc_w=self.loc_w, std_w=self.std_w,\n",
    "                                prior_b=self.prior_b, loc_b=self.loc_b, std_b=self.std_b,\n",
    "                                scaling_fn=self.scaling_fn))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18(softmax_temp=1.,\n",
    "             prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "             prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "            scaling_fn=None, bn=True):\n",
    "    return ClassificationModel(PreActResNet(PreActBlock,\n",
    "                                        [2,2,2,2], bn=bn,\n",
    "                                        prior_w=prior_w,\n",
    "                                       loc_w=loc_w,\n",
    "                                       std_w=std_w,\n",
    "                                       prior_b=prior_b,\n",
    "                                       loc_b=loc_b,\n",
    "                                       std_b=std_b,\n",
    "                                       scaling_fn=scaling_fn,), softmax_temp)\n",
    "\n",
    "def PreActResNet34(softmax_temp=1.,\n",
    "             prior_w=prior.Normal, loc_w=0., std_w=2**.5,\n",
    "             prior_b=prior.Normal, loc_b=0., std_b=1.,\n",
    "            scaling_fn=None, bn=True):\n",
    "    return ClassificationModel(PreActResNet(PreActBlock,\n",
    "                                        [3,4,6,3], bn=bn,\n",
    "                                        prior_w=prior_w,\n",
    "                                       loc_w=loc_w,\n",
    "                                       std_w=std_w,\n",
    "                                       prior_b=prior_b,\n",
    "                                       loc_b=loc_b,\n",
    "                                       std_b=std_b,\n",
    "                                       scaling_fn=scaling_fn,), softmax_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnn_priors.models import PreActResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10(device=device)\n",
    "\n",
    "dataloader_train = DataLoader(data.norm.train, batch_size=32, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(data.norm.test, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training criterion: nll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 6/1562 [00:00<00:44, 35.06it/s, loss=1.33]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 54.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 7/1562 [00:00<00:41, 37.56it/s, loss=1.09]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 66.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 7/1562 [00:00<00:41, 37.58it/s, loss=0.78]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 74.3 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 7/1562 [00:00<00:44, 35.23it/s, loss=0.34]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 74.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/1562 [00:00<00:56, 27.63it/s, loss=268.67] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 77.7 %\n",
      "Training criterion: potential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 4/1562 [00:00<01:03, 24.44it/s, loss=-4685.28]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test accuracy = 55.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 4/1562 [00:00<01:02, 24.76it/s, loss=-38600.84]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy = 58.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 5/1562 [00:00<00:57, 27.30it/s, loss=-116083.49]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Test accuracy = 58.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 4/1562 [00:00<01:02, 24.79it/s, loss=-231762.94]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Test accuracy = 57.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Test accuracy = 59.8 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "lr = 5e-4\n",
    "\n",
    "for criterion in [\"nll\", \"potential\"]:\n",
    "    print(f\"Training criterion: {criterion}\")\n",
    "    net = PreActResNet18(bn=True).to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        with tqdm(desc=f\"Epoch {epoch}\", total=len(dataloader_train), leave=False) as pbar:\n",
    "            for batch_x, batch_y in dataloader_train:\n",
    "                optimizer.zero_grad()\n",
    "                if criterion == \"nll\":\n",
    "                    loss = -net.log_likelihood_avg(batch_x, batch_y, len(dataloader_train.dataset))\n",
    "                elif criterion == \"potential\":\n",
    "                    loss = net.potential_avg(batch_x, batch_y, len(dataloader_train.dataset))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.update()\n",
    "                pbar.set_postfix({\"loss\": f\"{loss.item():.2f}\"})\n",
    "\n",
    "        total_acc = 0.\n",
    "        num_batches = 0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in dataloader_test:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                y_pred = net(batch_x).probs.argmax(axis=1)\n",
    "                total_acc += y_pred.eq(batch_y).float().mean().item()\n",
    "                num_batches += 1\n",
    "        acc = total_acc/num_batches\n",
    "        print(f\"Epoch {epoch}: Test accuracy = {acc*100:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGLD inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnn_priors.inference import SGLDRunner\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PreActResNet18(bn=True).to(device)\n",
    "\n",
    "n_samples = 2\n",
    "skip = 1\n",
    "cycles = 1\n",
    "warmup = 1\n",
    "burnin = 1\n",
    "lr = 5e-4\n",
    "temperature = 1.0\n",
    "momentum = 0.9\n",
    "precond_update = None\n",
    "    \n",
    "sample_epochs = n_samples * skip // cycles\n",
    "epochs_per_cycle = warmup + burnin + sample_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = SGLDRunner(model=model, dataloader=dataloader_train, epochs_per_cycle=epochs_per_cycle,\n",
    "                  warmup_epochs=warmup, sample_epochs=sample_epochs, learning_rate=lr,\n",
    "                  skip=skip, sampling_decay=True, cycles=cycles, temperature=temperature,\n",
    "                  momentum=momentum, precond_update=precond_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle 0, Sampling: 100%|██████████| 4/4 [04:05<00:00, 61.29s/it]\n"
     ]
    }
   ],
   "source": [
    "mcmc.run(progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_params = {k:v for k,v in model.state_dict().items() if \"bn\" in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lps = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    sample = dict((k, v[i].to(device)) for k, v in samples.items())\n",
    "    sampled_state_dict = {**sample, **bn_params}\n",
    "    with t.no_grad():\n",
    "        # TODO: get model.using_params() to work with batchnorm params\n",
    "        model.load_state_dict(sampled_state_dict)\n",
    "        lps_sample = []\n",
    "        for batch_x, batch_y in dataloader_test:\n",
    "            lps_batch = model(batch_x).log_prob(batch_y)\n",
    "            lps_sample.extend(list(lps_batch.cpu().numpy()))\n",
    "        lps.append(lps_sample)\n",
    "\n",
    "lps = t.tensor(lps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log prob = -1.49 +/- 1.17\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log prob = {lps.mean().item():.2f} +/- {lps.std().item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## He init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnn_priors.models import DenseNet, PreActResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_initialize(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight_prior.p\" in name:\n",
    "            torch.nn.init.kaiming_normal_(param.data, mode='fan_in', nonlinearity='relu')\n",
    "        elif \"bias_prior.p\" in name:\n",
    "            torch.nn.init.zeros_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DenseNet(20,10,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0377, -0.2506],\n",
       "        [-0.1723,  0.1209]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].weight_prior.p[:2,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2780, -1.3786], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias_prior.p[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_initialize(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0078,  0.2775],\n",
       "        [-0.3276,  0.1234]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].weight_prior.p[:2,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias_prior.p[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PreActResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.3668,  0.5335],\n",
       "          [ 0.6159, -0.2794]],\n",
       "\n",
       "         [[-0.7321,  1.1602],\n",
       "          [ 0.5006,  0.0309]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6768, -0.6904],\n",
       "          [-0.2288,  0.2639]],\n",
       "\n",
       "         [[-1.2357,  1.1778],\n",
       "          [ 0.7514,  0.4818]]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.conv1.weight_prior.p[:2,:2,:2,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_initialize(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1949,  0.0349],\n",
       "          [-0.2098, -0.0787]],\n",
       "\n",
       "         [[ 0.1343, -0.0710],\n",
       "          [ 0.0746, -0.1642]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4675, -0.7776],\n",
       "          [ 0.3416,  0.3063]],\n",
       "\n",
       "         [[ 0.2940, -0.1670],\n",
       "          [-0.2372,  0.4111]]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.conv1.weight_prior.p[:2,:2,:2,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
